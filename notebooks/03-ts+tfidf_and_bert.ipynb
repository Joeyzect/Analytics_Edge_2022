{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a35a8472-c691-421f-bd0b-e6209346f4f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "#viz\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2cd344ac-b31d-41f7-8f87-18967225ec41",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import PCA, KernelPCA\n",
    "import re\n",
    "import nltk\n",
    "import string\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "from gensim.models import Word2Vec, FastText\n",
    "import sklearn.feature_extraction.text as sk_text # TFIDF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce7d899e-e1b8-4c95-9438-320aa7060dca",
   "metadata": {},
   "source": [
    "# preprocess function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6b1cc7b7-9a4d-4177-97bb-23b293f7999d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/qinwenw/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home/qinwenw/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to /home/qinwenw/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# remove numbers\n",
    "def remove_num(text):\n",
    "    text_nonum = re.sub(r'\\d+', '', text)\n",
    "    text_nopunct = \"\".join([char.lower() for char in str(text_nonum) if char not in string.punctuation])\n",
    "    # substitute multiple whitespace with single whitespace\n",
    "    # Also, removes leading and trailing whitespaces\n",
    "    text_no_doublespace = re.sub('\\s+', ' ', text_nopunct).strip()\n",
    "    return text_nonum\n",
    "\n",
    "# remove_special_characters\n",
    "def remove_special_characters(text):\n",
    "    # define the pattern to keep\n",
    "    pat = r'[^a-zA-z0-9.,!?/:;\\\"\\'\\s]' \n",
    "    return re.sub(pat, '', text)\n",
    "\n",
    "# remove punctuation\n",
    "def remove_punctuation(text):\n",
    "    punctuationfree=\"\".join([i for i in text if str(i) not in string.punctuation])\n",
    "    return punctuationfree\n",
    "\n",
    "#  tokenization\n",
    "def tokenization(text):\n",
    "    tokens = re.split(' +',text)\n",
    "    return tokens\n",
    "\n",
    "# remove stopwords\n",
    "nltk.download('stopwords')\n",
    "my_stopwords = stopwords.words('english')\n",
    "my_stopwords.remove('be') # BE -> Back Ends\n",
    "def rm_stopwords(text):\n",
    "    return [i for i in text if i not in my_stopwords]\n",
    "\n",
    "# lemmatization\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n",
    "wordnet_lemmatizer = WordNetLemmatizer()\n",
    "def lemmatization(text):\n",
    "    lemm_text = [wordnet_lemmatizer.lemmatize(word) for word in text]\n",
    "    return lemm_text\n",
    "\n",
    "# remove_extra_whitespace_tabs\n",
    "def remove_extra_whitespace_tabs(text):\n",
    "    #pattern = r'^\\s+$|\\s+$'\n",
    "    pattern = r'^\\s*|\\s\\s*'\n",
    "    return re.sub(pattern, ' ', text).strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2dadfb68-e843-428d-8fac-139a42ea8b05",
   "metadata": {},
   "outputs": [],
   "source": [
    "review = pd.read_csv('./data/filtered/cleaned_review_modi_5.csv')\n",
    "review['month_year'] = pd.to_datetime(review[['year', 'month']].assign(DAY=1)).dt.to_period('M')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6b5245f5-279e-405d-9f3a-bf034b51bedb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop reviews with the same useful level\n",
    "# keep the last/ most recent one\n",
    "review_single = review.drop_duplicates(['business_id','year','month','useful'], keep='last')\n",
    "# select the most useful review\n",
    "# for each business for each year_month\n",
    "idx = review_single.groupby(['business_id','year','month'])['useful'].transform(max) == review_single['useful']\n",
    "review_most_useful = review_single[idx]\n",
    "review_most_useful = review_most_useful.drop(columns={'review_id','date','year','month','stars','useful','funny','cool'})\n",
    "review_most_useful = review_most_useful.sort_values(['business_id','month_year']).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "62ce40b2-71c1-40b8-a92f-fc7d66b2bdf1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>business_id</th>\n",
       "      <th>text</th>\n",
       "      <th>month_year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>--9e1ONYQuAa-CB_Rrw7Tw</td>\n",
       "      <td>I'm hardly ever in Vegas, and when I am here i...</td>\n",
       "      <td>2015-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>--9e1ONYQuAa-CB_Rrw7Tw</td>\n",
       "      <td>I'll start with this: I'm not a fan of Emeril ...</td>\n",
       "      <td>2015-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>--9e1ONYQuAa-CB_Rrw7Tw</td>\n",
       "      <td>Celebrated Labor Day weekend in Vegas and was ...</td>\n",
       "      <td>2015-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>--9e1ONYQuAa-CB_Rrw7Tw</td>\n",
       "      <td>I love love love Delmonico! I love the staff, ...</td>\n",
       "      <td>2015-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>--9e1ONYQuAa-CB_Rrw7Tw</td>\n",
       "      <td>Decided to try lunch today. I have had the Rib...</td>\n",
       "      <td>2015-05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              business_id                                               text  \\\n",
       "0  --9e1ONYQuAa-CB_Rrw7Tw  I'm hardly ever in Vegas, and when I am here i...   \n",
       "1  --9e1ONYQuAa-CB_Rrw7Tw  I'll start with this: I'm not a fan of Emeril ...   \n",
       "2  --9e1ONYQuAa-CB_Rrw7Tw  Celebrated Labor Day weekend in Vegas and was ...   \n",
       "3  --9e1ONYQuAa-CB_Rrw7Tw  I love love love Delmonico! I love the staff, ...   \n",
       "4  --9e1ONYQuAa-CB_Rrw7Tw  Decided to try lunch today. I have had the Rib...   \n",
       "\n",
       "  month_year  \n",
       "0    2015-01  \n",
       "1    2015-02  \n",
       "2    2015-03  \n",
       "3    2015-04  \n",
       "4    2015-05  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review_most_useful.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "deb90f5f-7260-4218-acd5-5170a398e221",
   "metadata": {},
   "outputs": [],
   "source": [
    "review_most_useful.loc[:,('text')] = review_most_useful.loc[:,('text')].apply(\n",
    "        lambda x: lemmatization(rm_stopwords(tokenization(remove_punctuation(remove_extra_whitespace_tabs(remove_num(remove_special_characters(x.lower())))))))\n",
    "    )\n",
    "review_most_useful.loc[:,('text')] = review_most_useful.loc[:,('text')].apply(lambda x: ' '.join(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8c2f14c8-bae2-4430-8770-8e4e34bb037d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>business_id</th>\n",
       "      <th>text</th>\n",
       "      <th>month_year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>--9e1ONYQuAa-CB_Rrw7Tw</td>\n",
       "      <td>im hardly ever vega rage forage hah hah must a...</td>\n",
       "      <td>2015-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>--9e1ONYQuAa-CB_Rrw7Tw</td>\n",
       "      <td>ill start im fan emeril lagasse dont know ive ...</td>\n",
       "      <td>2015-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>--9e1ONYQuAa-CB_Rrw7Tw</td>\n",
       "      <td>celebrated labor day weekend vega looking good...</td>\n",
       "      <td>2015-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>--9e1ONYQuAa-CB_Rrw7Tw</td>\n",
       "      <td>love love love delmonico love staff food ambia...</td>\n",
       "      <td>2015-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>--9e1ONYQuAa-CB_Rrw7Tw</td>\n",
       "      <td>decided try lunch today rib steak loved today ...</td>\n",
       "      <td>2015-05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              business_id                                               text  \\\n",
       "0  --9e1ONYQuAa-CB_Rrw7Tw  im hardly ever vega rage forage hah hah must a...   \n",
       "1  --9e1ONYQuAa-CB_Rrw7Tw  ill start im fan emeril lagasse dont know ive ...   \n",
       "2  --9e1ONYQuAa-CB_Rrw7Tw  celebrated labor day weekend vega looking good...   \n",
       "3  --9e1ONYQuAa-CB_Rrw7Tw  love love love delmonico love staff food ambia...   \n",
       "4  --9e1ONYQuAa-CB_Rrw7Tw  decided try lunch today rib steak loved today ...   \n",
       "\n",
       "  month_year  \n",
       "0    2015-01  \n",
       "1    2015-02  \n",
       "2    2015-03  \n",
       "3    2015-04  \n",
       "4    2015-05  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review_most_useful.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71e6bda1-7f22-4035-9275-2f7cca7b8208",
   "metadata": {},
   "source": [
    "## TFIDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "00eeb767-0d4c-4aac-8c2c-67e5502f80ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/qinwenw/.local/lib/python3.9/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# vectorizer = TfidfVectorizer()\n",
    "vectorizer = sk_text.TfidfVectorizer(max_features=1000, lowercase=True, analyzer='word',\n",
    "                                     stop_words= 'english',ngram_range=(1,1))\n",
    "vectors = vectorizer.fit_transform(review_most_useful['text'])\n",
    "feature_names = vectorizer.get_feature_names()\n",
    "dense = vectors.todense()\n",
    "denselist = dense.tolist()\n",
    "df_tfidf = pd.DataFrame(denselist, columns=feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "531c3161-96ae-4496-8a71-d071786d19c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>able</th>\n",
       "      <th>absolutely</th>\n",
       "      <th>actual</th>\n",
       "      <th>actually</th>\n",
       "      <th>add</th>\n",
       "      <th>added</th>\n",
       "      <th>addition</th>\n",
       "      <th>additional</th>\n",
       "      <th>afternoon</th>\n",
       "      <th>ago</th>\n",
       "      <th>...</th>\n",
       "      <th>year</th>\n",
       "      <th>yelp</th>\n",
       "      <th>yes</th>\n",
       "      <th>york</th>\n",
       "      <th>youd</th>\n",
       "      <th>youll</th>\n",
       "      <th>youre</th>\n",
       "      <th>youve</th>\n",
       "      <th>yum</th>\n",
       "      <th>yummy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.262122</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.131745</td>\n",
       "      <td>0.044476</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.049307</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.066665</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.20052</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1000 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   able  absolutely    actual  actually  add  added  addition  additional  \\\n",
       "0   0.0    0.262122  0.000000  0.000000  0.0    0.0       0.0         0.0   \n",
       "1   0.0    0.000000  0.131745  0.044476  0.0    0.0       0.0         0.0   \n",
       "2   0.0    0.000000  0.000000  0.000000  0.0    0.0       0.0         0.0   \n",
       "3   0.0    0.000000  0.000000  0.000000  0.0    0.0       0.0         0.0   \n",
       "4   0.0    0.000000  0.000000  0.000000  0.0    0.0       0.0         0.0   \n",
       "\n",
       "   afternoon  ago  ...  year  yelp       yes  york      youd  youll    youre  \\\n",
       "0        0.0  0.0  ...   0.0   0.0  0.000000   0.0  0.000000    0.0  0.00000   \n",
       "1        0.0  0.0  ...   0.0   0.0  0.049307   0.0  0.066665    0.0  0.20052   \n",
       "2        0.0  0.0  ...   0.0   0.0  0.000000   0.0  0.000000    0.0  0.00000   \n",
       "3        0.0  0.0  ...   0.0   0.0  0.000000   0.0  0.000000    0.0  0.00000   \n",
       "4        0.0  0.0  ...   0.0   0.0  0.000000   0.0  0.000000    0.0  0.00000   \n",
       "\n",
       "   youve  yum  yummy  \n",
       "0    0.0  0.0    0.0  \n",
       "1    0.0  0.0    0.0  \n",
       "2    0.0  0.0    0.0  \n",
       "3    0.0  0.0    0.0  \n",
       "4    0.0  0.0    0.0  \n",
       "\n",
       "[5 rows x 1000 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tfidf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8ca82f35-6cbe-4df9-ad3e-703a0a3bbdb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reduce to 5 dimentions\n",
    "n=5\n",
    "pca = PCA(n_components=n)\n",
    "text_pca = pca.fit_transform(df_tfidf)\n",
    "df_pca = pd.DataFrame(text_pca)\n",
    "df_pca.columns = ['text_pca'+str(i) for i in range(1,n+1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "118832d5-7f18-4834-971a-21cbdc825f2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df =  pd.concat([review_most_useful, df_pca], axis=1)\n",
    "df = df.drop(columns='text')\n",
    "# df.to_csv(\"./data/filtered/cleaned_review_modi_3_tfidf.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "abddc9d0-d066-4a05-aab0-2d57d691bd5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>business_id</th>\n",
       "      <th>month_year</th>\n",
       "      <th>text_pca1</th>\n",
       "      <th>text_pca2</th>\n",
       "      <th>text_pca3</th>\n",
       "      <th>text_pca4</th>\n",
       "      <th>text_pca5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>--9e1ONYQuAa-CB_Rrw7Tw</td>\n",
       "      <td>2015-01</td>\n",
       "      <td>0.037837</td>\n",
       "      <td>-0.022495</td>\n",
       "      <td>0.048339</td>\n",
       "      <td>-0.126852</td>\n",
       "      <td>-0.086118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>--9e1ONYQuAa-CB_Rrw7Tw</td>\n",
       "      <td>2015-02</td>\n",
       "      <td>-0.040089</td>\n",
       "      <td>-0.038087</td>\n",
       "      <td>0.064798</td>\n",
       "      <td>0.120718</td>\n",
       "      <td>-0.064648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>--9e1ONYQuAa-CB_Rrw7Tw</td>\n",
       "      <td>2015-03</td>\n",
       "      <td>-0.106095</td>\n",
       "      <td>-0.019336</td>\n",
       "      <td>0.144173</td>\n",
       "      <td>0.049278</td>\n",
       "      <td>-0.071613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>--9e1ONYQuAa-CB_Rrw7Tw</td>\n",
       "      <td>2015-04</td>\n",
       "      <td>-0.017845</td>\n",
       "      <td>-0.033601</td>\n",
       "      <td>0.018613</td>\n",
       "      <td>-0.067188</td>\n",
       "      <td>-0.084294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>--9e1ONYQuAa-CB_Rrw7Tw</td>\n",
       "      <td>2015-05</td>\n",
       "      <td>-0.070687</td>\n",
       "      <td>-0.033032</td>\n",
       "      <td>0.034046</td>\n",
       "      <td>0.019868</td>\n",
       "      <td>-0.073832</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              business_id month_year  text_pca1  text_pca2  text_pca3  \\\n",
       "0  --9e1ONYQuAa-CB_Rrw7Tw    2015-01   0.037837  -0.022495   0.048339   \n",
       "1  --9e1ONYQuAa-CB_Rrw7Tw    2015-02  -0.040089  -0.038087   0.064798   \n",
       "2  --9e1ONYQuAa-CB_Rrw7Tw    2015-03  -0.106095  -0.019336   0.144173   \n",
       "3  --9e1ONYQuAa-CB_Rrw7Tw    2015-04  -0.017845  -0.033601   0.018613   \n",
       "4  --9e1ONYQuAa-CB_Rrw7Tw    2015-05  -0.070687  -0.033032   0.034046   \n",
       "\n",
       "   text_pca4  text_pca5  \n",
       "0  -0.126852  -0.086118  \n",
       "1   0.120718  -0.064648  \n",
       "2   0.049278  -0.071613  \n",
       "3  -0.067188  -0.084294  \n",
       "4   0.019868  -0.073832  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "656fdfac-55ba-4f70-bbad-1d1c7239c9d0",
   "metadata": {},
   "source": [
    "## BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "05c16ea7-2ccd-4781-80fb-046e8165b213",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_transform.bias', 'vocab_transform.weight', 'vocab_layer_norm.weight', 'vocab_projector.bias', 'vocab_layer_norm.bias', 'vocab_projector.weight']\n",
      "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
    "model = AutoModel.from_pretrained(\"distilbert-base-uncased\").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "78a24625-be2a-460a-9dfe-26d6c2e05c02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>business_id</th>\n",
       "      <th>text</th>\n",
       "      <th>month_year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>--9e1ONYQuAa-CB_Rrw7Tw</td>\n",
       "      <td>im hardly ever vega rage forage hah hah must a...</td>\n",
       "      <td>2015-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>--9e1ONYQuAa-CB_Rrw7Tw</td>\n",
       "      <td>ill start im fan emeril lagasse dont know ive ...</td>\n",
       "      <td>2015-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>--9e1ONYQuAa-CB_Rrw7Tw</td>\n",
       "      <td>celebrated labor day weekend vega looking good...</td>\n",
       "      <td>2015-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>--9e1ONYQuAa-CB_Rrw7Tw</td>\n",
       "      <td>love love love delmonico love staff food ambia...</td>\n",
       "      <td>2015-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>--9e1ONYQuAa-CB_Rrw7Tw</td>\n",
       "      <td>decided try lunch today rib steak loved today ...</td>\n",
       "      <td>2015-05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              business_id                                               text  \\\n",
       "0  --9e1ONYQuAa-CB_Rrw7Tw  im hardly ever vega rage forage hah hah must a...   \n",
       "1  --9e1ONYQuAa-CB_Rrw7Tw  ill start im fan emeril lagasse dont know ive ...   \n",
       "2  --9e1ONYQuAa-CB_Rrw7Tw  celebrated labor day weekend vega looking good...   \n",
       "3  --9e1ONYQuAa-CB_Rrw7Tw  love love love delmonico love staff food ambia...   \n",
       "4  --9e1ONYQuAa-CB_Rrw7Tw  decided try lunch today rib steak loved today ...   \n",
       "\n",
       "  month_year  \n",
       "0    2015-01  \n",
       "1    2015-02  \n",
       "2    2015-03  \n",
       "3    2015-04  \n",
       "4    2015-05  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review_most_useful.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "58b33d87-8c66-485b-badd-5f6f5cff6cd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_14642/1607318060.py:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  tokenized_review = {k:torch.tensor(v).to(device) for k,v in tokenized_review.items()}\n"
     ]
    }
   ],
   "source": [
    "tokenized_review = tokenizer(review_most_useful['text'].values.tolist(),\n",
    "                             padding = True, truncation = True, return_tensors=\"pt\")\n",
    "\n",
    "#move on device (GPU)\n",
    "tokenized_review = {k:torch.tensor(v).to(device) for k,v in tokenized_review.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b3f1dfa7-5c9f-4b7f-8026-d9dd1e9932f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[  101, 10047,  6684,  ...,     0,     0,     0],\n",
       "         [  101,  5665,  2707,  ...,     0,     0,     0],\n",
       "         [  101,  6334,  4450,  ...,     0,     0,     0],\n",
       "         ...,\n",
       "         [  101,  2307,  4157,  ...,     0,     0,     0],\n",
       "         [  101,  2307,  2312,  ...,     0,     0,     0],\n",
       "         [  101,  2173,  8966,  ...,     0,     0,     0]]),\n",
       " 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
       "         [1, 1, 1,  ..., 0, 0, 0],\n",
       "         [1, 1, 1,  ..., 0, 0, 0],\n",
       "         ...,\n",
       "         [1, 1, 1,  ..., 0, 0, 0],\n",
       "         [1, 1, 1,  ..., 0, 0, 0],\n",
       "         [1, 1, 1,  ..., 0, 0, 0]])}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e2f89d6-f5fe-4370-b5d9-71e39074bd7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    hidden_review = model(**tokenized_review) #dim : [batch_size(nr_sentences), tokens, emb_dim]\n",
    "\n",
    "#get only the [CLS] hidden states\n",
    "cls_review = tokenized_review.last_hidden_state[:,0,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dedbc9dd-3078-4cfd-8758-bcc27a953374",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e717f0d-39b4-43a1-8817-6b20d0d7b24d",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 5\n",
    "pca = PCA(n_components=n)\n",
    "description_pca = pca.fit_transform(cls_review)\n",
    "temp = pd.DataFrame(description_pca)\n",
    "temp.columns = ['Description_pca'+str(i) for i in range(1,description_n+1)]\n",
    "df =  pd.concat([df, temp], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86048c6f-c340-4253-a2ea-e03853b23f9f",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e2c6469-d33a-4b6c-91bb-bcf6c8aa8239",
   "metadata": {},
   "outputs": [],
   "source": [
    "# timeseries = review1.join(review2)\n",
    "timeseries = review3.join(review2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "737940c1-920b-4240-9f35-051177072bb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "timeseries.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "666ea160-985e-4fbf-a5b6-722250be6312",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_lags(df, lags, cols=['stars', 'text', 'useful', 'funny', 'cool', 'sentiment_score']):\n",
    "    lag_array = []\n",
    "    for lag in lags:\n",
    "        lagged = df.groupby('business_id').shift(lag)\n",
    "        lagged.columns = [f'{col}_lag_{lag}' for col in lagged.columns]\n",
    "        lag_array.append(lagged)\n",
    "    lags = pd.concat(lag_array, axis=1)\n",
    "    return pd.concat([df, lags], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2d145d7-c02d-49b2-8603-eac5bd008232",
   "metadata": {},
   "outputs": [],
   "source": [
    "lagged_df = make_lags(timeseries, np.arange(1, 13))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "286f4a6c-9d21-43ea-80c4-aada0ff09c1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "lagged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04d86595-fd42-43dc-b703-dd5de9a9270a",
   "metadata": {},
   "outputs": [],
   "source": [
    "next_month = make_lags(timeseries, [-1])\n",
    "next_month_avg_stars = next_month[(next_month.index.get_level_values(1) >= '2016-01') &\n",
    "                                  (next_month.index.get_level_values(1) != '2017-12')][['stars_lag_-1']].rename(\n",
    "    columns={'stars_lag_-1': 'next_month_avg_stars'})\n",
    "final_lagged_df = pd.concat([lagged_df[(lagged_df.index.get_level_values(1) >= '2016-01') &\n",
    "                                       (lagged_df.index.get_level_values(1) != '2017-12')], next_month_avg_stars], axis=1)\n",
    "\n",
    "#attach business data\n",
    "\n",
    "businesses = pd.read_csv('./data/yelp_business.csv')\n",
    "mybusinesses = businesses[businesses['business_id'].isin(review['business_id'])].reset_index(drop=True)\n",
    "\n",
    "useful_vars = mybusinesses[['business_id', 'latitude', 'longitude', 'review_count']]\n",
    "\n",
    "final_df = final_lagged_df.reset_index().merge(useful_vars,\n",
    "                        on='business_id').set_index(['business_id', 'month_year']).sort_index(level=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74b25cb5-5060-42ea-8cb2-875bce29c781",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbb1b50f-baee-4c42-8dfd-d0b2662e1920",
   "metadata": {},
   "outputs": [],
   "source": [
    "# timeseries test train split\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "\n",
    "X = final_lagged_df[final_lagged_df.index.get_level_values(1) <= '2017-07'].drop('next_month_avg_stars', axis=1)\n",
    "y = final_lagged_df[final_lagged_df.index.get_level_values(1) <= '2017-07']['next_month_avg_stars']\n",
    "\n",
    "tscv = TimeSeriesSplit(n_splits=5, gap=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e082b2c-ef68-4244-b2b1-21bb6fe011b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make pipeline\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import ElasticNet, Lasso, Ridge\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "warnings.simplefilter(\"ignore\", UserWarning)\n",
    "\n",
    "pipe = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('regressor', ElasticNet())\n",
    "])\n",
    "\n",
    "param_grid = {\n",
    "    #'regressor__fit_intercept': [True, False],\n",
    "    'regressor__alpha': [0, 0.1, 0.2],\n",
    "    'regressor__l1_ratio': [0.05, 0.1, 0.15]\n",
    "}\n",
    "\n",
    "grid = GridSearchCV(pipe, param_grid, cv=tscv, scoring='neg_mean_squared_error', n_jobs=-1, verbose=1)\n",
    "\n",
    "grid.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf019ee5-8767-4e4e-8c55-2ad69cb3a322",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fcd09b3-9b14-48cd-ac9e-7d3db010ecad",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b8797c1-4f01-46da-9d2c-e912bbcf9fea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use 2017-08 as test set\n",
    "test_X = final_lagged_df[final_lagged_df.index.get_level_values(1) == '2017-08'].drop('next_month_avg_stars', axis=1)\n",
    "test_y = final_lagged_df[final_lagged_df.index.get_level_values(1) == '2017-08']['next_month_avg_stars']\n",
    "\n",
    "print(\"MSE: \", -grid.score(test_X, test_y))\n",
    "\n",
    "# Rsquared\n",
    "\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "print(\"R-squared\", r2_score(test_y, grid.predict(test_X)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e4a2e14-9bb6-44e3-8708-682b5e712658",
   "metadata": {},
   "source": [
    "**without** sentiment\n",
    "\n",
    "MSE = 0.11009040821693132\n",
    "\n",
    "R^2 = 0.7860813104464417\n",
    "\n",
    "**with** sentimetent\n",
    "\n",
    "MSE = 0.13907533021966362\n",
    "\n",
    "R^2 = 0.7398459301388225\n",
    "\n",
    "**TFIDF**\n",
    "\n",
    "MSE = 0.14055024452036893\n",
    "\n",
    "R^2 = 0.7370869580233588"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f35a031-558f-4988-bc39-a20b5c37eea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# xgboost pipeline\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "pipe = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('regressor', XGBRegressor())\n",
    "])\n",
    "\n",
    "param_grid = {\n",
    "    'regressor': [XGBRegressor()],\n",
    "    'regressor__max_depth': [2,3],\n",
    "    'regressor__learning_rate': [0.1],\n",
    "    'regressor__n_estimators': [100],\n",
    "    'regressor__subsample': [1],\n",
    "    'regressor__colsample_bytree': [1],\n",
    "    'regressor__reg_alpha': [0.1, 0.2, 0.3],\n",
    "}\n",
    "\n",
    "xgb_grid = GridSearchCV(pipe, param_grid, cv=tscv, scoring='neg_mean_squared_error', n_jobs=-1, verbose=1)\n",
    "\n",
    "xgb_grid.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9a3c2ee-0a97-4f51-952a-c9dded520e52",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd1a6198-8f91-4bda-bdca-13c29af806e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#.250 - max depth 2\n",
    "print('best_score: ',xgb_grid.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0c2753c-3126-408d-99bc-b68c931223da",
   "metadata": {},
   "source": [
    "**without** sentiment:\n",
    "\n",
    "best_score:  -0.11382132077111447\n",
    "\n",
    "**with** sentiment:\n",
    "\n",
    "best_score:  -0.1416801342235987\n",
    "\n",
    "**TFIDF**:\n",
    "\n",
    "best_score:  -0.14559988200558513"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be847c83-4a7a-4112-82d4-5c6502cd4a52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use 2017-08 as test set\n",
    "\n",
    "test_X = final_lagged_df[final_lagged_df.index.get_level_values(1) == '2017-08'].drop('next_month_avg_stars', axis=1)\n",
    "test_y = final_lagged_df[final_lagged_df.index.get_level_values(1) == '2017-08']['next_month_avg_stars']\n",
    "\n",
    "print(\"MSE: \", -xgb_grid.score(test_X, test_y))\n",
    "\n",
    "# Rsquared\n",
    "\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "print(\"R-squared\", r2_score(test_y, xgb_grid.predict(test_X)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5611bab7-4554-473a-9395-8afbda910c98",
   "metadata": {},
   "source": [
    "**without** sentiment:\n",
    "\n",
    "MSE:  0.11338180969045816\n",
    "\n",
    "R-squared 0.7796857279300784\n",
    "\n",
    "**with** sentiment:\n",
    "\n",
    "MSE:  0.13901107527057768\n",
    "\n",
    "R-squared 0.7399661253343832"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eadabff-53a0-41e9-9b6a-a798d37958c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Baseline model\n",
    "\n",
    "#using the average 2017 rating\n",
    "avg_2017_pred = final_lagged_df[final_lagged_df.index.get_level_values(1) == '2017-08']['stars'].mean()\n",
    "\n",
    "print(\"MSE with average of all:\", mean_squared_error(final_lagged_df[final_lagged_df.index.get_level_values(1) == '2017-08']['next_month_avg_stars'], np.repeat(avg_2017_pred, 143)))\n",
    "\n",
    "#using the average rating for each business\n",
    "\n",
    "print(\"MSE with previous month of each business:\", mean_squared_error(final_lagged_df[final_lagged_df.index.get_level_values(1) == '2017-08']['next_month_avg_stars'], final_lagged_df[final_lagged_df.index.get_level_values(1) == '2017-08']['stars']))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
